\section{Optimizations}
\subsection{Output Privitization}
\hspace{\parindent}Output privatization is a parallel computing optimization technique where multiple sub-copies of the output are computed to reduce the number of memory access conflicts. When multiple threads attempt to access the same memory address, they must wait to sequentially perform their operation. 

This technique led to the greatest single speedup. With a single private copy made for each block of threads, there was about a 2x speedup.
 
\subsubsection{Multiple Private Copies}
\hspace{\parindent}The next logical step from one private copy is to create multiple private copies. However, creating the maximum number of copies is unfeasible. The more copies that are created, the fewer blocks that can be run on a multiprocessor at the same time. 

The final kernel uses a model to determine the best number of copies to create. It estimates memory access speed and the number of rounds required for each number of shared histograms. The model is based on the model described in a paper on 2-body statistics by N. Pitaksirianan et al. However, during testing, the model did not weigh the cost of a conflict enough. This led to it creating fewer copies than was optimal in certain scenarios. To remedy this, the conflict cost was weighted more.

To further increase the number of possible copies, the size of each private copy was reduced. The maximum size of each bucket was reduced since each private copy counter will not need to hold the final value of the histogram.
\subsubsection{Parallel Reduction}
\hspace{\parindent}Since multiple sub-copies of the output were created, they must be combined into the final output. The optimized kernel first combines the local copies of each block into a single local copy. It does this through a parallel reduction. Each block then adds its local copy into the final output copy.

This would likely be improved by copying all of the reduced block copies from shared into global, then reducing in parallel there. In a partial implementation, it increased performance by about 4\%. However, this was not made fully working in time.


\subsection{Tiling}
\hspace{\parindent}Tiling is an optimization technique where values that will be repeatedly used will be stored in faster memory to reduce the cost of accessing global memory. The input data can be divided into sections. Every element of this section must compute its distance from each anchor value in the block. This brought a modest speed increase to the kernel.

\subsubsection{Intra-Tile Distance Balancing}
\hspace{\parindent}On the step for computing the distances of points within the tile, there is control divergence. The result of this is that some resources will be reserved but not used. A partially working version was implemented and saw a marginal speed increase. This was also not able to be made fully working in time.

\subsection{Memory Coalescing}
\hspace{\parindent}When something in memory is accessed, it becomes quicker to access the adjacent memory. Making all the threads access sequential elements in the input data can improve the access times. This also led to a marginal speed increase. 

\subsection{Other Optimizations}
\hspace{\parindent}A tweak that saw a noticeable performance increase is running with a block size that is close to the number of output buckets. So for running with a bucket width of 500 (80 bins), 64 threads will work the best. Another optimization that proved to be worthwhile was to change the square root function from the standard double precision to a double precision reciprocal square root and then multiply that by the starting value. 
